<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Large Language Models for Blockchain Security and Analytics: A Survey</title>
  <style>
    :root {
      --bg: #0b1020;
      --card: #121a33;
      --text: #e8ecff;
      --muted: #b7c0ff;
      --border: rgba(255,255,255,0.14);
      --hl: rgba(255, 214, 102, 0.22);
      --hl-border: rgba(255, 214, 102, 0.35);
      --link: #9cc2ff;
    }

    body {
      margin: 0;
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";
      background: radial-gradient(1200px 600px at 20% 0%, #18234a 0%, var(--bg) 55%) fixed;
      color: var(--text);
      line-height: 1.5;
    }

    .wrap {
      max-width: 1180px;
      margin: 0 auto;
      padding: 28px 18px 44px;
    }

    header {
      background: linear-gradient(180deg, rgba(255,255,255,0.08), rgba(255,255,255,0.04));
      border: 1px solid var(--border);
      border-radius: 16px;
      padding: 18px 18px 14px;
      box-shadow: 0 12px 30px rgba(0,0,0,0.25);
    }

    h1 {
      font-size: 1.55rem;
      margin: 0 0 10px;
      letter-spacing: 0.2px;
    }

    .authors {
      color: var(--muted);
      margin: 0;
      font-size: 0.98rem;
    }

    .authors strong {
      color: var(--text);
      font-weight: 650;
    }

    .meta {
      margin-top: 10px;
      display: grid;
      gap: 6px;
      color: var(--muted);
      font-size: 0.95rem;
    }

    .meta code {
      background: rgba(255,255,255,0.06);
      border: 1px solid rgba(255,255,255,0.10);
      padding: 2px 6px;
      border-radius: 8px;
      color: var(--text);
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.92em;
    }

    .section {
      margin-top: 16px;
      background: rgba(255,255,255,0.05);
      border: 1px solid var(--border);
      border-radius: 16px;
      padding: 16px 16px 18px;
      box-shadow: 0 10px 26px rgba(0,0,0,0.22);
    }

    .section h2 {
      margin: 0 0 8px;
      font-size: 1.1rem;
      letter-spacing: 0.15px;
    }

    .section p {
      margin: 0;
      color: var(--muted);
    }

    .controls {
      margin-top: 14px;
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      align-items: center;
    }

    .controls label {
      font-size: 0.92rem;
      color: var(--muted);
    }

    input[type="search"] {
      flex: 1;
      min-width: 240px;
      padding: 10px 12px;
      border-radius: 12px;
      border: 1px solid rgba(255,255,255,0.18);
      background: rgba(5, 8, 18, 0.55);
      color: var(--text);
      outline: none;
    }

    input[type="search"]:focus {
      border-color: rgba(156,194,255,0.75);
      box-shadow: 0 0 0 4px rgba(156,194,255,0.12);
    }

    .pill {
      display: inline-flex;
      gap: 8px;
      align-items: center;
      border: 1px solid rgba(255,255,255,0.16);
      background: rgba(255,255,255,0.06);
      padding: 8px 10px;
      border-radius: 999px;
      color: var(--muted);
      font-size: 0.9rem;
    }

    .pill b {
      color: var(--text);
      font-weight: 650;
    }

    .tableWrap {
      margin-top: 12px;
      overflow: auto;
      border-radius: 14px;
      border: 1px solid var(--border);
      background: rgba(2, 4, 10, 0.35);
    }

    table {
      width: 100%;
      border-collapse: separate;
      border-spacing: 0;
      min-width: 980px;
    }

    thead th {
      position: sticky;
      top: 0;
      z-index: 2;
      background: rgba(12, 18, 40, 0.95);
      color: var(--text);
      text-align: left;
      font-size: 0.9rem;
      padding: 12px 12px;
      border-bottom: 1px solid rgba(255,255,255,0.12);
      white-space: nowrap;
    }

    tbody td {
      padding: 12px 12px;
      border-bottom: 1px solid rgba(255,255,255,0.10);
      vertical-align: top;
      color: var(--text);
      font-size: 0.92rem;
    }

    tbody tr:hover td {
      background: rgba(255,255,255,0.03);
    }

    th.hl, td.hl {
      background: var(--hl);
      border-bottom-color: var(--hl-border);
    }

    a {
      color: var(--link);
      text-decoration: none;
      font-weight: 650;
    }

    a:hover {
      text-decoration: underline;
    }

    .note {
      margin-top: 10px;
      color: var(--muted);
      font-size: 0.9rem;
    }

    .legend {
      margin-top: 10px;
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      align-items: center;
      color: var(--muted);
      font-size: 0.9rem;
    }

    .swatch {
      width: 14px;
      height: 14px;
      border-radius: 4px;
      background: var(--hl);
      border: 1px solid var(--hl-border);
      display: inline-block;
      vertical-align: middle;
      margin-right: 6px;
    }

    footer {
      margin-top: 16px;
      color: rgba(232,236,255,0.72);
      font-size: 0.85rem;
    }

    .criteriaText {
      display: grid;
      gap: 10px;
      margin-top: 8px;
    }
    .criteriaText p { margin: 0; }

    .criteriaGrid {
      margin-top: 12px;
      display: grid;
      gap: 12px;
      grid-template-columns: 1fr;
    }
    @media (min-width: 860px) {
      .criteriaGrid { grid-template-columns: 1fr 1fr; }
    }

    .figureCard {
      border: 1px solid var(--border);
      background: rgba(2, 4, 10, 0.35);
      border-radius: 14px;
      overflow: hidden;
    }
    .figureCard img {
      width: 100%;
      height: auto;
      display: block;
    }
    .figureCard figcaption {
      padding: 10px 12px 12px;
      color: var(--muted);
      font-size: 0.92rem;
      border-top: 1px solid rgba(255,255,255,0.08);
    }
  </style>
</head>
<body>
  <div class="wrap">

    <header>
      <h1>Large Language Models for Blockchain Security and Analytics: A Survey</h1>
      <p class="authors"><strong>Collette Eguakun Okundia</strong><sup>1</sup>, <strong>Cuneyt Gurcan Akcora</strong><sup>2</sup>, <strong>Arijit Khan</strong><sup>1</sup></p>
      <div class="meta">
        <div><sup>1</sup>Bowling Green State University, Ohio, USA</div>
        <div><sup>2</sup>University of Central Florida, Florida, USA</div>
        <div>Contact: <code>{ceguaku, arijitk}@bgsu.edu</code>, <code>cuneyt.akcora@ucf.edu</code></div>
      </div>
    </header>

    <section class="section" id="paper-selection-criteria">
      <h2>Paper Selection Criteria</h2>

      <div class="criteriaText">
        <p>
          We conducted a structured survey of recent work on large language models applied to blockchain security and
          financial analytics, targeting publications from January 2020 through October 2025. This timeframe spans the
          widespread adoption of transformer-based models, the emergence of instruction-tuned and code-focused LLMs, and
          the more recent use of retrieval-augmented and agentic systems. We queried major academic venues and
          repositories, including IEEE Xplore, ACM Digital Library, Springer, arXiv, and Google Scholar, using
          combinations of keywords related to large language models, blockchain systems, smart contracts, transactions,
          decentralized finance, fraud detection, and financial analytics.
        </p>

        <p>
          The initial search returned just under five hundred papers. After removing duplicates and clearly irrelevant
          works, approximately two hundred papers were examined at the abstract level, followed by full-text review of
          around one hundred studies. The final corpus comprises seventy-eight papers that make substantive operational
          use of LLMs for blockchain-related tasks. We included both peer-reviewed publications and well-documented
          preprints, reflecting standard practice in AI research. Works were excluded when LLMs were mentioned only
          tangentially, when contributions were purely conceptual without empirical or technical validation, or when
          methodological details were insufficient to support comparison.
        </p>

        <p>
          The selected literature reveals a sharp acceleration in research activity after late 2022, following the public
          release of ChatGPT. Figure 1 situates this growth alongside major developments in LLM capabilities and
          significant events in blockchain security and DeFi. From 2023 onward, the number of LLM-based blockchain
          studies increased rapidly, with particularly strong concentration in smart contract auditing and vulnerability
          detection. At the same time, real-world incidents continued to escalate in scale, with hundreds of smart
          contract and DeFi attacks reported in 2024 alone, reinforcing the demand for automated analysis methods capable
          of reasoning about complex logic and cross-contract interactions <span style="color: var(--muted);">[Cymetrics Tech Blog, 2024]</span>.
        </p>

        <p>
          Across the surveyed papers, we observe substantial heterogeneity in model choice, data scale, and evaluation
          practice. Proprietary GPT-family models dominate early work, while more recent studies increasingly explore
          open-source models and lightweight fine-tuning for scalability. Dataset sizes vary by several orders of
          magnitude, ranging from analyses of individual contracts to studies involving over one hundred thousand
          transactions or addresses. Smart contract auditing accounts for a disproportionate share of the literature,
          while transaction anomaly detection, fraud analysis, DeFi-scale reasoning, and financial modeling receive
          comparatively limited attention. These imbalances motivate a taxonomy that goes beyond task labels and instead
          characterizes systems by the functional role played by the LLM, enabling comparison across domains that would
          otherwise appear unrelated.
        </p>

      </div>

      <div class="criteriaGrid">
        <figure class="figureCard">
          <img src="figures/figure1_timeline.png"
               alt="Timeline of key milestones in LLM development and blockchain security from 2020 to 2025"
               loading="lazy">
          <figcaption>
            <b>Figure 1:</b> Timeline of key milestones in LLM development and blockchain security from 2020 to 2025,
            showing how GPT-3, ChatGPT, and open-source LLMs emerge alongside major bridge hacks, complex DeFi protocol
            failures, the first LLM-based smart contract auditing tools, RAG and agentic security pipelines, and the
            adoption of on-chain real-time monitoring in operations.
          </figcaption>
        </figure>

        <figure class="figureCard">
          <img src="figures/figure2_heatmap.png"
               alt="Heatmap of LLM role usage across application domains"
               loading="lazy">
          <figcaption>
            <b>Figure 2:</b> Heatmap of LLM role usage across application domains (counts indicative).
          </figcaption>
        </figure>
      </div>
    </section>

    <section class="section">
      <p>
        Below is a consolidated table of all papers used in our research and survey synthesis. The highlighted columns
        represent the core comparison fields we focused on when categorizing work across blockchain security and
        analytics applications.
      </p>

      <div class="controls">
        <label for="q">Search table:</label>
        <input id="q" type="search" placeholder="Type to filter by title, task, LLMs used, dataset, venue, year, etc." autocomplete="off" />
        <span class="pill"><b id="countShown">0</b> shown</span>
        <span class="pill"><b id="countTotal">0</b> total</span>
      </div>

      

      <div class="tableWrap">
        <table id="papersTable">
<thead><tr>
<th>NO</th>
<th class="hl">Title</th>
<th>Venue</th>
<th class="hl">Year</th>
<th class="hl">Paper Link</th>
<th class="hl">Application Category</th>
<th class="hl">Task</th>
<th>LLM Roles</th>
<th class="hl">LLMs Used</th>
<th class="hl">Fine-Tuning</th>
<th class="hl">Retrieval-augmented generation</th>
<th class="hl">Agentic Orchestration</th>
<th class="hl">Tool Calling</th>
<th class="hl">Datasets Used</th>
</tr></thead>
<tbody>
<tr>
<td>1</td>
<td class="hl">Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering</td>
<td>IEEE Access</td>
<td class="hl">2024</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Enhancing%20Zero-Shot%20Crypto%20Sentiment%20With%20Fine-Tuned%20Language%20Model%20and%20Prompt%20Engineering" target="_blank" rel="noopener">link</a></td>
<td class="hl">Community Analysis</td>
<td class="hl">Crypto Sentiment Analysis</td>
<td>Classifier (C)</td>
<td class="hl">DistilBERT, MiniLM, FLAN-T5</td>
<td class="hl">Instruction-based Fine-tuning, SFT</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">Neo (Tweet), Reddit, Bitcoin Sentiment (Tweet), Cryptocurrency Sentiment (Tweet)</td>
</tr>

<tr>
<td>2</td>
<td class="hl">CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain</td>
<td>arXiv</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=CodeBC%3A%20A%20More%20Secure%20Large%20Language%20Model%20for%20Smart%20Contract%20Code%20Generation%20in%20Blockchain" target="_blank" rel="noopener">link</a></td>
<td class="hl">Smart Contract; Smart Contract Development</td>
<td class="hl">Smart Contract Development</td>
<td>Generator (G)</td>
<td class="hl">CodeLlama</td>
<td class="hl">Three-stage Fine-tuning</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">SASCsmall-F, Blockchain-HumanEval</td>
</tr>

<tr>
<td>3</td>
<td class="hl">Blockchain Meets Machine Learning: A Survey</td>
<td>Journal of Big Data</td>
<td class="hl">2024</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Blockchain%20Meets%20Machine%20Learning%3A%20A%20Survey" target="_blank" rel="noopener">link</a></td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td>Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
</tr>

<tr>
<td>4</td>
<td class="hl">Cryptocurrency Smart Contracts for Distributed Consensus of Public Randomness</td>
<td>International Symposium on Stabilization, Safety, and Security of Distributed Systems (SSS)</td>
<td class="hl">2017</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Cryptocurrency%20Smart%20Contracts%20for%20Distributed%20Consensus%20of%20Public%20Randomness" target="_blank" rel="noopener">link</a></td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td>Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
</tr>

<tr>
<td>5</td>
<td class="hl">LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework</td>
<td>arXiv</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=LLM-BSCVM%3A%20An%20LLM-Based%20Blockchain%20Smart%20Contract%20Vulnerability%20Management%20Framework" target="_blank" rel="noopener">link</a></td>
<td class="hl">Smart Contract</td>
<td class="hl">Smart Contract Auditing</td>
<td>Classifier (C), Explainer (E)</td>
<td class="hl">CodeLlama, CodeBERT, CodeT5, Llama; Fine-tuned Detection Model (CodeLlama)</td>
<td class="hl">Decompose-Retrieve-Generate</td>
<td class="hl">None</td>
<td class="hl">Multi-agent Framework</td>
<td class="hl">None</td>
<td class="hl">TrustLLM, Smart Contract Audit Reports from Dappscan</td>
</tr>

<tr>
<td>6</td>
<td class="hl">Language Models are Few-Shot Learners</td>
<td>NeurIPS</td>
<td class="hl">2020</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Language%20Models%20are%20Few-Shot%20Learners" target="_blank" rel="noopener">link</a></td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td>Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
<td class="hl">Not specified</td>
</tr>

<tr>
<td>7</td>
<td class="hl">BPMN-LLM: Transforming BPMN Models into Smart Contracts Using Large Language Models</td>
<td>IEEE Software</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=BPMN-LLM%3A%20Transforming%20BPMN%20Models%20into%20Smart%20Contracts%20Using%20Large%20Language%20Models" target="_blank" rel="noopener">link</a></td>
<td class="hl">Smart Contract</td>
<td class="hl">Smart Contract Development</td>
<td>Translator (T)</td>
<td class="hl">GPT-3.5, GPT-4.0, Gemini</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">Legal Contracts (e.g., sales, auctions, purchases, leases, voting, services, and lending)</td>
</tr>

<tr>
<td>8</td>
<td class="hl">Scalable Blockchain Analytics: an LLM-Powered Approach</td>
<td>IEEE International Conference on Blockchain and Cryptocurrency</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Scalable%20Blockchain%20Analytics%3A%20an%20LLM-Powered%20Approach" target="_blank" rel="noopener">link</a></td>
<td class="hl">Blockchain Data Analysis</td>
<td class="hl">Stake Address Analysis, Staking Pool Dynamics, Delegated Stake Distribution, Rewards Analysis</td>
<td>Synthesizer (S), Tool User (U)</td>
<td class="hl">GPT-4o</td>
<td class="hl">None</td>
<td class="hl">Data Retrieval, Template Retrieval</td>
<td class="hl">Multi-agent: SQL Agent, Analysis Agent, Visualization Agent</td>
<td class="hl">get_table_list, get_tables_schema, understand_csv_schema, get_schema_tool, get_chart_index, etc.</td>
<td class="hl">Cardano Blockchain Data</td>
</tr>

<tr>
<td>9</td>
<td class="hl">When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are We?</td>
<td>arXiv</td>
<td class="hl">2024</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=When%20ChatGPT%20Meets%20Smart%20Contract%20Vulnerability%20Detection%3A%20How%20Far%20Are%20We%3F" target="_blank" rel="noopener">link</a></td>
<td class="hl">Smart Contract; Smart Contract Auditing</td>
<td class="hl">Smart Contract Auditing</td>
<td>Classifier (C)</td>
<td class="hl">gpt-3.5-turbo-0613, gpt-4o-2024-05-13, gpt-4-0613</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None (but compared against vulnerability detection tools)</td>
<td class="hl">smartbugs</td>
</tr>

<tr>
<td>10</td>
<td class="hl">Llm4fuzz: Guided Fuzzing of Smart Contracts with Large Language Models</td>
<td>arXiv</td>
<td class="hl">2024</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Llm4fuzz%3A%20Guided%20Fuzzing%20of%20Smart%20Contracts%20with%20Large%20Language%20Models" target="_blank" rel="noopener">link</a></td>
<td class="hl">Smart Contract</td>
<td class="hl">Smart Contract Dynamic Analysis</td>
<td>Generator (G)</td>
<td class="hl">Llama 2 70B</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None (but compared against testing and static analysis tools)</td>
<td class="hl">117 Previously Exploited Smart Contract Projects</td>
</tr>

<tr>
<td>11</td>
<td class="hl">Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs</td>
<td>IEEE International Conference on Software Testing, Verification and Validation</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Accessible%20Smart%20Contracts%20Verification%3A%20Synthesizing%20Formal%20Models%20with%20Tamed%20LLMs" target="_blank" rel="noopener">link</a></td>
<td class="hl">Smart Contract</td>
<td class="hl">Smart Contract Auditing</td>
<td>Translator (T), Tool User (T)</td>
<td class="hl">GPT-4o</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">cosmwasm-to-quint, rustc_plugin, etc.</td>
<td class="hl">CosmWasm Smart Contracts</td>
</tr>

<tr>
<td>12</td>
<td class="hl">Large Language Model-Based Conversational Recommender System for Personalizing Long-term Cryptocurrency Portfolio Recommendation</td>
<td>International Conference on Information and Communication Technology</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Large%20Language%20Model-Based%20Conversational%20Recommender%20System%20for%20Personalizing%20Long-term%20Cryptocurrency%20Portfolio%20Recommendation" target="_blank" rel="noopener">link</a></td>
<td class="hl">Markets</td>
<td class="hl">Portfolio /Investment</td>
<td>Generator (G)</td>
<td class="hl">GPT-4o</td>
<td class="hl">Fine-tuning as System, User, and Assistant Level</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">scraping https:// coinmarketcap.com and https://coingecko.com</td>
</tr>

<tr>
<td>13</td>
<td class="hl">INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agents</td>
<td>ACL</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=INVESTORBENCH%3A%20A%20Benchmark%20for%20Financial%20Decision-Making%20Tasks%20with%20LLM-based%20Agents" target="_blank" rel="noopener">link</a></td>
<td class="hl">Markets</td>
<td class="hl">Portfolio /Investment</td>
<td>Generator (G), Synthesizer (S), Tool User (U)</td>
<td class="hl">Fine-tuned LLMs</td>
<td class="hl">Not specified</td>
<td class="hl">Retrieval from a Vector Database in the Long-Term Memory Data Warehouse</td>
<td class="hl">LLM Trading Agents</td>
<td class="hl">Tabular Data Readers, API callers</td>
<td class="hl">Bitcoin and Ethereum Datasets</td>
</tr>

<tr>
<td>14</td>
<td class="hl">Using Large Language Models for Enhanced Fraud Analysis and Detection in Blockchain based Health Insurance Claims</td>
<td>Scientific Reports</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Using%20Large%20Language%20Models%20for%20Enhanced%20Fraud%20Analysis%20and%20Detection%20in%20Blockchain%20based%20Health%20Insurance%20Claims" target="_blank" rel="noopener">link</a></td>
<td class="hl">Transactions</td>
<td class="hl">Fraud Detection</td>
<td>Classifier (C), Synthesizer (S), Explainer (E), Tool User (U)</td>
<td class="hl">GPT-4o</td>
<td class="hl">None</td>
<td class="hl">Intelligent Retrieval and Analysis of Relevant Clinical Information</td>
<td class="hl">Fraud Detection Backend Multi-agents</td>
<td class="hl">Function Calling Tool for Automated Execution of SC Functions based on User Requests</td>
<td class="hl">Public Clinical Datasets</td>
</tr>

<tr>
<td>15</td>
<td class="hl">Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection</td>
<td>arXiv</td>
<td class="hl">2025</td>
<td class="hl"><a href="https://www.semanticscholar.org/search?q=Explain%20First%2C%20Trust%20Later%3A%20LLM-Augmented%20Explanations%20for%20Graph-Based%20Crypto%20Anomaly%20Detection" target="_blank" rel="noopener">link</a></td>
<td class="hl">Transactions</td>
<td class="hl">Anomaly Detection</td>
<td>Explainer (E)</td>
<td class="hl">ChatGPT</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">None</td>
<td class="hl">Elliptic++</td>
</tr>
</tbody>
</tbody></table>
      </div>

      
    </section>

    

  </div>

  <script>
    (function() {
      const input = document.getElementById('q');
      const table = document.getElementById('papersTable');
      const tbody = table.querySelector('tbody');
      const rows = Array.from(tbody.querySelectorAll('tr'));
      const countShown = document.getElementById('countShown');
      const countTotal = document.getElementById('countTotal');

      countTotal.textContent = String(rows.length);

      // Fill empty cells in specific columns with 'None' to match the Excel convention.
      const headerCells = Array.from(table.querySelectorAll('thead th'));
      const colIndex = (name) => headerCells.findIndex(th => (th.textContent || '').trim().toLowerCase() === name.toLowerCase());

      const ragIdx = colIndex('Retrieval-augmented generation');
      const agentIdx = colIndex('Agentic Orchestration');
      const toolIdx = colIndex('Tool Calling');
      const fillIdxs = [ragIdx, agentIdx, toolIdx].filter(i => i >= 0);

      for (const tr of rows) {
        const tds = tr.querySelectorAll('td');
        for (const i of fillIdxs) {
          const td = tds[i];
          if (td && (td.textContent || '').trim() === '') {
            td.textContent = 'None';
          }
        }
      }

      function normalize(s) {
        return (s || '').toString().toLowerCase();
      }

      function applyFilter() {
        const q = normalize(input.value).trim();
        let shown = 0;
        for (const tr of rows) {
          const text = normalize(tr.innerText);
          const match = !q || text.indexOf(q) !== -1;
          tr.style.display = match ? '' : 'none';
          if (match) shown++;
        }
        countShown.textContent = String(shown);
      }

      input.addEventListener('input', applyFilter);
      applyFilter();
    })();
  </script>
</body>
</html>


